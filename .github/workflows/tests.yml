name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ["3.9", "3.10", "3.11", "3.12"]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}-${{ hashFiles('**/setup.py') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install system dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg

    - name: Install system dependencies (macOS)
      if: matrix.os == 'macos-latest'
      run: |
        brew install ffmpeg

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[test]"
        pip install pytest-cov pytest-asyncio pytest-timeout pytest-mock

    - name: Lint with flake8
      run: |
        pip install flake8
        # stop the build if there are Python syntax errors or undefined names
        flake8 src --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 src --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Type check with mypy
      run: |
        pip install mypy
        mypy src --ignore-missing-imports --no-strict-optional
      continue-on-error: true  # Don't fail CI on type errors for now

    - name: Run unit tests
      run: |
        pytest tests/unit -v --tb=short --durations=10 \
          --cov=src --cov-report=xml --cov-report=term-missing

    - name: Run integration tests
      run: |
        pytest tests/integration -v --tb=short --durations=10 \
          -m "not requires_model" \
          --cov=src --cov-append --cov-report=xml --cov-report=term-missing
      continue-on-error: true  # Integration tests may be flaky

    - name: Run performance tests (quick)
      run: |
        pytest tests/performance -v --tb=short \
          -m "not slow" \
          --durations=10 \
          --cov=src --cov-append --cov-report=xml --cov-report=term-missing
      continue-on-error: true  # Performance tests may fail on slower systems

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false
        verbose: true

  test-with-models:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg
        python -m pip install --upgrade pip
        pip install -e ".[test,full]"
        pip install pytest-cov pytest-asyncio pytest-timeout pytest-mock

    - name: Cache models
      uses: actions/cache@v3
      with:
        path: ~/.cache/whisper-models
        key: ${{ runner.os }}-whisper-models-v1

    - name: Download test models (if available)
      run: |
        # Download small models for testing
        mkdir -p ~/.cache/whisper-models
        # Add model download logic here if needed
      continue-on-error: true

    - name: Run tests requiring models
      run: |
        pytest tests -v --tb=short \
          -m "requires_model" \
          --cov=src --cov-report=xml --cov-report=term-missing
      continue-on-error: true

  performance-benchmarks:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg
        python -m pip install --upgrade pip
        pip install -e ".[test]"
        pip install pytest-benchmark

    - name: Run performance benchmarks
      run: |
        pytest tests/performance -v --tb=short \
          --benchmark-only \
          --benchmark-json=benchmark.json
      continue-on-error: true

    - name: Store benchmark results
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: Python Benchmark
        tool: 'pytest'
        output-file-path: benchmark.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        comment-on-alert: true
        alert-threshold: '200%'
        fail-on-alert: false

  security-scan:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install security scanning tools
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit semgrep

    - name: Run safety check
      run: |
        pip freeze | safety check --json --output safety-report.json
      continue-on-error: true

    - name: Run bandit security scan
      run: |
        bandit -r src -f json -o bandit-report.json
      continue-on-error: true

    - name: Run semgrep scan
      run: |
        semgrep --config=auto src --json --output=semgrep-report.json
      continue-on-error: true

    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          safety-report.json
          bandit-report.json
          semgrep-report.json
      if: always()

  code-quality:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install code quality tools
      run: |
        python -m pip install --upgrade pip
        pip install black isort flake8 pylint

    - name: Check code formatting with black
      run: |
        black --check --diff src tests

    - name: Check import sorting with isort
      run: |
        isort --check-only --diff src tests

    - name: Lint with pylint
      run: |
        pylint src --output-format=json --reports=y > pylint-report.json
      continue-on-error: true

    - name: Upload code quality reports
      uses: actions/upload-artifact@v3
      with:
        name: code-quality-reports
        path: pylint-report.json
      if: always()