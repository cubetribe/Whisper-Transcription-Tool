# Whisper Transcription Tool (v0.9)

Ein modulares Python-Tool zur Transkription und Auswertung von Audio- und Videodaten mit Whisper.cpp, vollst√§ndig portabel und plattformunabh√§ngig mit automatischer Audioextraktion.

## üöÄ Schnellstart

### Option 1: Verwendung der neuen virtuellen Umgebung (empfohlen)
```bash
cd "/Users/denniswestermann/Desktop/Coding Projekte/whisper_clean"
source venv_new/bin/activate
python -m src.whisper_transcription_tool.main web --port 8090
```

### Option 2: Verwendung des Start-Skripts
```bash
cd "/Users/denniswestermann/Desktop/Coding Projekte/whisper_clean"
./start_server.sh
```

### Option 3: Doppelklick auf Launcher
- **QuickLauncher.command** - Startet die Anwendung mit automatischer Pfaderkennung
- **Whisper Transkriptionstool.command** - Alternative Startmethode

## ‚ö†Ô∏è Wichtige Hinweise

- **Projektpfad:** `/Users/denniswestermann/Desktop/Coding Projekte/whisper_clean`
- **Virtuelle Umgebung:** Verwendet `venv_new` (oder `venv` als Fallback)
- **Konfiguration:** Liegt in `~/.whisper_tool.json`
- **Whisper Binary:** `deps/whisper.cpp/build/bin/whisper-cli` (muss ausf√ºhrbar sein: `chmod +x`)
- **Modelle:** Werden im Verzeichnis `models/` gespeichert
- **Transkriptionen:** Werden in `transcriptions/` gespeichert

## √úbersicht

---

## SRT-Optionen: Zeilenumbruch-Steuerung

Ab Version 0.8.1.2 kannst du im SRT-Export folgende Optionen nutzen:

- **Maximale Zeichen pro Zeile:** √úber einen Slider einstellbar (20‚Äì120).
- **Zeilenumbruch f√ºr Untertitel aktivieren:** Checkbox, standardm√§√üig aktiviert. Ist sie aktiviert, werden Untertitel in maximal zwei Zeilen (nach Zeichenl√§nge) umgebrochen. Ist sie deaktiviert, wird jeder Untertitel einzeilig ausgegeben (kein Zeilenumbruch, auch bei langen S√§tzen).

**Hinweis:**
- Die Einstellung wirkt sich direkt auf die erzeugte SRT-Datei aus.
- Die Option ist sowohl f√ºr Einzel- als auch Batch-Transkriptionen verf√ºgbar.
- Zeilenumbr√ºche in SRT werden jetzt immer als \r\n gespeichert (maximale Kompatibilit√§t mit Playern und Editoren).

---

Dieses Projekt bietet eine modulare L√∂sung zur Transkription von Audiodaten mit Whisper.cpp, optimiert f√ºr Apple Silicon (M4-Chip). Die gesamte L√∂sung l√§uft lokal auf Ihrem Mac - ohne API-Abh√§ngigkeiten bei der Transkription, was maximale Datenschutzkontrolle und Unabh√§ngigkeit gew√§hrleistet.

### Hauptmerkmale

- **Lokale Transkription** mit Whisper.cpp, optimiert f√ºr Apple Silicon
- **Direkte Videotranskription** mit automatischer Audioextraktion
- **Modulare Architektur** f√ºr einfache Erweiterbarkeit und Wartung
- **Volle Portabilit√§t** mit dynamischen Pfaden und plattformunabh√§ngiger Konfiguration
- **Einfacher Start** mit dem neuen QuickLauncher.command
- **Standard-Modell** 'large-v3-turbo' f√ºr optimale Ergebnisse
- **Verarbeitung von Telefonaufnahmen** mit zwei separaten Spuren
- **Chatbot-Schnittstelle** zur Analyse von Transkripten
- **Zentrale Konfiguration** mit allen Daten im Projektverzeichnis

## Modulare Architektur und Portabilit√§t

Das Projekt ist in vier Hauptmodule unterteilt und unterst√ºtzt dank der dynamischen Pfadfindung nun verschiedene Betriebssysteme und Verzeichnisstrukturen:

1. **Modul 1: Lokale Audio-Transkription**
   - Transkription lokaler .mp3- und .wav-Dateien mit Whisper.cpp
   - Unterst√ºtzung f√ºr verschiedene Modellgr√∂√üen und Sprachen
   - Ausgabe in verschiedenen Formaten (.txt, .srt, .vtt)
   - Standardkonforme SRT-Untertitel mit pr√§zisen Zeitangaben
   - Flexible Steuerung der Zeilenumbr√ºche in SRT-Untertiteln (einzeilig/zweizeilig)

2. **Modul 2: Video-Audioextraktion**
   - Extraktion des Tons aus Videos (.mp4, .mov) mit FFmpeg
   - Konvertierung in optimiertes Format f√ºr Whisper
   - Nahtlose Integration mit dem Transkriptionsmodul

3. **Modul 3: Telefonaufnahme-Verarbeitung**
   - Import von zwei separaten Audiospuren (Teilnehmer A und B)
   - Separate Transkription beider Spuren
   - Zusammenf√ºhrung in ein dialogartiges Transkript

4. **Modul 4: Chatbot zur Transkriptanalyse**
   - Lokale Vektordatenbank f√ºr Transkripte
   - Semantische Suche in Transkripten
   - CLI- und Web-Schnittstelle (Gradio)

5. **Modul 5: Live-Telefonat mit Echtzeit-Aufzeichnung** (in Entwicklung)
   - Aufzeichnung von VoIP-Telefongespr√§chen
   - Automatische Trennung und Kennzeichnung der Gespr√§chsteilnehmer
   - Direkte Transkription mit Sprechererkennung
   - Nahtlose Integration mit dem Chatbot-Modul zur Gespr√§chsanalyse

## Architektur√ºbersicht

![Systemarchitektur](docs/architecture_v0.6.png)
*Aktualisierte Architektur mit Video-Extraktionsmodul*

## Unterst√ºtzte Formate
| Video | Audio |
|-------|-------|
| MP4   | WAV   |
| MOV   | MP3   |
| AVI   | FLAC  |

## Aktueller Status & Ausblick (Version 0.9)

- **Version:** 0.9 (Stand: 2025-05-24)
- **Kernfunktionalit√§t:** FFmpeg-basierte Video-Audioextraktion, Batch-Audio-Transkription, BlackHole-Audio-Aufnahme, standardkonforme SRT-Dateierzeugung
- **Letzte Aktualisierung:** 2025-05-11

### Neue Funktionen in Version 0.9:

- **WebSocket-Implementierung**
  - Verbesserte Event-√úbertragung zwischen Server und Client
  - Echtzeit-Fortschrittsanzeige w√§hrend der Transkription
  - Reaktivere Benutzeroberfl√§che f√ºr lange Verarbeitungsprozesse

- **Erweiterte Videokonvertierung**
  - Fortschrittsanzeige w√§hrend der Videokonvertierung
  - Detaillierte Statusmeldungen w√§hrend der Verarbeitung
  - Verbesserte Fehlerbehandlung bei der Audioextraktion

- **Automatisierte FFmpeg-Integration**
  - Automatische Installation von FFmpeg im Setup-Skript
  - Plattformunabh√§ngige Konfiguration und Erkennung
  - Verbesserte Kompatibilit√§t mit verschiedenen Systemen

- **Erweiterte Dateihandhabung**
  - Verbesserter Datei-Download aus benutzerdefinierten Verzeichnissen
  - Optimierte Pfadverarbeitung f√ºr Ausgabedateien
  - Konsistentes Verhalten bei relativen und absoluten Pfaden

### Kommende Verbesserungen:

- **Anpassbares Ausgabeverzeichnis**
  - Wiederherstellung der Funktionalit√§t zur freien Wahl des Ausgabeverzeichnisses
  - Verbesserte Download-Links f√ºr generierte Dateien

### Neue Funktionen in Version 0.6.1:

- **Verbesserte Dokumentation**
  - Aktualisierte Projektdokumentation f√ºr alle Module
  - Optimierte README mit aktuellen Funktionen und Status
  - Erweiterte Fehlerbehandlungsdokumentation

- **Stabilere Modellverwaltung**
  - Verbesserungen im Download-System f√ºr Modelle
  - Robustere Fehlerbehandlung bei der Modellverarbeitung

### Neue Funktionen in Version 0.6:

- **Erweiterte Modellverwaltung**
  - Detaillierte Modellinformationen (Gr√∂√üe, Beschreibung, Anwendungsempfehlungen)
  - Automatische Abbildung von vereinfachten Modellnamen auf aktuelle Whisper.cpp-Versionen
  - Verbesserte Benutzeroberfl√§che mit Tab-Navigation zwischen empfohlenen und allen Modellen
  - Optimierte Fehlerbehandlung beim Modell-Download

- **Verbesserte Video-Extraktion**
  - Integration von FFmpeg zur Extraktion von Audio aus verschiedenen Videoformaten
  - Automatische Erkennung und optimale Konvertierung verschiedener Videoformate
  - Nahtlose Weiterleitung zur Transkription nach erfolgreicher Extraktion

- **Ausstehende Verbesserungen:**
  - Explizite UI-Unterst√ºtzung f√ºr Videoformate
  - Automatische FFmpeg-Installation im Setup-Skript
  - Fortschrittsanzeige und Feedback w√§hrend Videokonvertierung
  - Erweiterte Fehlerbehandlung f√ºr problematische Videodateien

## Installation

### Voraussetzungen

- macOS mit Apple Silicon (M1, M2, M3, M4)
- Python 3.11 oder h√∂her
- FFmpeg (f√ºr Videoextraktion)
- Whisper.cpp (bereits im Projekt enthalten)

### Schnellinstallation f√ºr bestehende Installation

```bash
# 1. Zum Projektverzeichnis wechseln
cd "/Users/denniswestermann/Desktop/Coding Projekte/whisper_clean"

# 2. Neue virtuelle Umgebung erstellen (falls nicht vorhanden)
python3 -m venv venv_new

# 3. Virtuelle Umgebung aktivieren
source venv_new/bin/activate

# 4. Abh√§ngigkeiten installieren
pip install -r requirements.txt

# 5. App im Entwicklungsmodus installieren
pip install -e .

# 6. Whisper-CLI ausf√ºhrbar machen
chmod +x deps/whisper.cpp/build/bin/whisper-cli

# 7. Server starten
python -m src.whisper_transcription_tool.main web --port 8090
```

### Vollst√§ndige Neuinstallation

```bash
# Repository klonen (falls noch nicht vorhanden)
git clone https://github.com/yourusername/whisper_transcription_tool.git
cd whisper_transcription_tool

# Installation √ºber das Setup-Skript
bash install.sh
```

### Zus√§tzliche Abh√§ngigkeiten

F√ºr die Chatbot-Funktionalit√§t:

```bash
pip install "whisper-transcription-tool[chatbot]"
```

F√ºr die Web-Schnittstelle:

```bash
pip install "whisper-transcription-tool[web]"
```

F√ºr standardkonforme SRT-Untertiteldateien:

```bash
pip install pysrt
```

F√ºr Entwickler:

```bash
pip install "whisper-transcription-tool[dev]"
```

## Verwendung

### Web-Interface (empfohlen)

Nach dem Start ist die Web-Oberfl√§che unter http://localhost:8090 verf√ºgbar.

### Kommandozeile

#### Transkription einer Audiodatei

```bash
whisper-tool transcribe path/to/audio.mp3 --model large-v3-turbo
```

### Extraktion und Transkription eines Videos

```bash
whisper-tool extract path/to/video.mp4
whisper-tool transcribe path/to/video.wav
```

### Verarbeitung von Telefonaufnahmen

```bash
whisper-tool phone path/to/caller_a.mp3 path/to/caller_b.mp3
```

### Starten des Chatbots

```bash
whisper-tool chatbot --transcript path/to/transcript.txt
```

Oder mit Web-Schnittstelle:

```bash
whisper-tool chatbot --transcript path/to/transcript.txt --mode web
```

## Konfiguration

Die Standardkonfiguration kann √ºber eine JSON- oder YAML-Datei angepasst werden. Legen Sie eine Datei unter einem der folgenden Pfade an:

- `~/.whisper_tool.json`
- `~/.whisper_tool.yaml`
- `~/.config/whisper_tool/config.json`

Beispielkonfiguration:

```json
{
  "whisper": {
    "model_path": "/path/to/models",
    "default_model": "medium",
    "threads": 4
  },
  "ffmpeg": {
    "binary_path": "/usr/local/bin/ffmpeg",
    "audio_format": "wav",
    "sample_rate": 16000
  },
  "output": {
    "default_directory": "~/transcriptions",
    "default_format": "txt"
  },
  "chatbot": {
    "mode": "local",
    "model": "mistral-7b"
  }
}
```

## Entwicklung

### Projektstruktur

```
whisper_transcription_tool/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ whisper_transcription_tool/
‚îÇ       ‚îú‚îÄ‚îÄ core/                  # Gemeinsame Funktionalit√§t
‚îÇ       ‚îú‚îÄ‚îÄ module1_transcribe/    # Transkriptionsmodul
‚îÇ       ‚îú‚îÄ‚îÄ module2_extract/       # Videoextraktionsmodul
‚îÇ       ‚îú‚îÄ‚îÄ module3_phone/         # Telefonaufnahme-Modul
‚îÇ       ‚îî‚îÄ‚îÄ module4_chatbot/       # Chatbot-Modul
‚îú‚îÄ‚îÄ tests/                         # Testf√§lle
‚îú‚îÄ‚îÄ docs/                          # Dokumentation
‚îú‚îÄ‚îÄ examples/                      # Beispiele
‚îî‚îÄ‚îÄ .github/                       # GitHub-Workflows
```

### Entwicklungsumgebung einrichten

```bash
# Repository klonen
git clone https://github.com/yourusername/whisper_transcription_tool.git
cd whisper_transcription_tool

# Entwicklungsabh√§ngigkeiten installieren
pip install -e ".[dev]"

# Pre-commit-Hooks einrichten
pre-commit install
```

### Tests ausf√ºhren

```bash
pytest
```

## Mitwirken

Wir freuen uns √ºber Beitr√§ge! Bitte lesen Sie [CONTRIBUTING.md](CONTRIBUTING.md) f√ºr Details zum Prozess f√ºr Pull Requests.

## Lizenz

Dieses Projekt steht unter der MIT-Lizenz - siehe [LICENSE](LICENSE) f√ºr Details.

## Roadmap

- [ ] Integration von Sprecheridentifikation
- [ ] Unterst√ºtzung f√ºr weitere Sprachen
- [ ] Batch-Verarbeitung f√ºr gro√üe Mengen von Dateien
- [ ] Verbesserung der Chatbot-Funktionalit√§t mit lokalen LLMs
- [ ] GUI-Anwendung f√ºr macOS

## H√§ufig gestellte Fragen

### Welche Whisper-Modelle werden unterst√ºtzt?

Alle Modelle von Whisper.cpp werden unterst√ºtzt: tiny, base, small, medium und large.

### Wie viel Speicher ben√∂tigen die Modelle?

- tiny: ~75MB
- base: ~150MB
- small: ~500MB
- medium: ~1.5GB
- large: ~3GB

### Funktioniert das Tool auch auf Intel Macs?

Ja, das Tool funktioniert auch auf Intel Macs, ist aber f√ºr Apple Silicon optimiert.

### Kann ich das Tool mit OpenAI's Whisper API verwenden?

Nein, dieses Tool ist speziell f√ºr die lokale Verarbeitung mit Whisper.cpp konzipiert. F√ºr API-basierte L√∂sungen gibt es andere Tools.

## Kontakt

Bei Fragen oder Problemen erstellen Sie bitte ein [GitHub Issue](https://github.com/yourusername/whisper_transcription_tool/issues).

---

*Zuletzt aktualisiert: 2025-04-20*

## Web-Oberfl√§che

*   Starten mit `python -m src.whisper_transcription_tool.main web`.
*   Erm√∂glicht das Hochladen von Audio-/Videodateien (Video wird automatisch extrahiert).
*   Auswahl von Whisper-Modell, Sprache (optional) und Ausgabeformat.
*   Unterst√ºtzt Batch-Verarbeitung mehrerer Dateien.
*   **NEU:** Bietet eine eigene Seite zur **Modellverwaltung** (`/models`):
    *   Zeigt verf√ºgbare Whisper-Modelle und deren Download-Status an.
    *   Erm√∂glicht das **Herunterladen** von Modellen direkt √ºber die Oberfl√§che.
    *   Zeigt einen detaillierten **Fortschrittsdialog** w√§hrend des Downloads an (Gr√∂√üe, Geschwindigkeit, verbleibende Zeit).
    *   Erm√∂glicht das **√Ñndern des Verzeichnisses**, in dem die Modelle gespeichert werden.
*   Zeigt Transkriptionsfortschritt in Echtzeit √ºber WebSockets an.
*   Stellt Ergebnisse tabellarisch dar mit Download-Links f√ºr jedes Format.

## Bekannte Einschr√§nkungen

- Die Fortschrittsanzeige bei Modell-Downloads zeigt nur an, dass ein Download l√§uft, aber keine Live-Updates
- WebSocket-Kommunikation f√ºr Echtzeit-Updates wird in Version 0.6.0 neu implementiert
- Download-Geschwindigkeit ist aktuell langsam (wird in zuk√ºnftiger Version optimiert)

## Bekannte Probleme

Siehe [PROBLEMS.md](PROBLEMS.md) f√ºr eine Liste bekannter technischer Herausforderungen und deren L√∂sungen.

## Roadmap

- Version 0.5.0: Video-Audioextraktion (aktuell in Entwicklung)
- Version 0.6.0: √úberarbeitete WebSocket-Implementierung

### Geplante Features

| Modul | Beschreibung | Status |
|-------|--------------|-------------|
| System Audio Capture | Parallele Aufnahme von Mikrofon und Systemaudio | ‚úÖ Implementiert (v0.5.0) |

## Aufnahme von Kommunikationsanwendungen

Das Tool unterst√ºtzt die Aufnahme von Gespr√§chen aus verschiedenen Kommunikationsanwendungen mit getrennten Audiospuren:

### Voraussetzungen

- [BlackHole](https://github.com/ExistentialAudio/BlackHole) Audio-Treiber (installierbar √ºber `brew install --cask blackhole-2ch`)
- Unterst√ºtzte Anwendungen: Microsoft Teams, Discord, Zoom, Skype, WebEx, Google Meet, etc.

### Installation der Aufnahmefunktion

Die Aufnahmefunktion erfordert zus√§tzliche Abh√§ngigkeiten. Folgen Sie diesen Schritten:

```bash
# BlackHole Virtual Audio Driver installieren
brew install --cask blackhole-2ch

# Nach der Installation einen Neustart durchf√ºhren oder Audio-Dienste neustarten

# Audio-Abh√§ngigkeiten installieren (in der Projektumgebung)
cd /Pfad/zu/whisper_clean
source venv/bin/activate  # Falls noch nicht aktiviert
pip install -e ".[web]"   # Installiert im Entwicklungsmodus mit allen Web-Komponenten
```

> **Hinweis:** Bei Abh√§ngigkeitsproblemen stellen Sie sicher, dass neue Pakete sowohl in `requirements.txt` als auch in den entsprechenden `extras_require`-Abschnitten in `setup.py` registriert sind.

### Aufnahmeprozess

1. Unter dem "Telefon"-Tab den Bereich "Live-Aufnahme" ausw√§hlen
2. Eigenes Mikrofon als Eingabeger√§t w√§hlen
3. BlackHole als Ausgabeger√§t w√§hlen
4. Audio-Routing in den Systemeinstellungen konfigurieren:
   - √ñffnen Sie Systemeinstellungen ‚Üí Ton
   - Setzen Sie BlackHole als Ausgabeger√§t
   - In Ihrer Kommunikationsanwendung: Normales Mikrofon als Eingabe w√§hlen
5. Aufnahme starten und Gespr√§ch beginnen

Das Tool zeichnet zwei getrennte Audiospuren auf:
- Ihre Stimme (Mikrofoneingang)
- Die Stimme Ihres Gespr√§chspartners (Systemton)

Beide Spuren k√∂nnen separat oder kombiniert transkribiert werden.
